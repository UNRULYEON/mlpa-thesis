\styledchapter[Discussie]{discussie}
Gedurende de scriptie is literatuuronderzoek gedaan naar ML pipelines en orkestratietools. Daarnaast zijn een aantal experimenten uitgevoerd om de potentie van een ML pipeline en orkestratietool te valideren. 

De resultaten van het experiment met ML pipelines laten zien dat het trainen van modellen op een gestructureerde en reproduceerbare wijze gedaan kan worden. In \autoref{sec:ch4-advies} is uitgelegd hoe ML versimpeld kan worden voor de developer door extra stappen toe te voegen. Dit kan niet alleen gebruikt worden door NGTI maar ook andere bedrijven die geïnteresseerd zijn in het toepassen van ML. Een stap verder zou zijn dat een standaard wordt geïntroduceerd dat wordt toegepast door industrieleiders zoals Google, Microsoft en Azure. Momenteel hebben ze hun eigen variant wat betekent dat specifieke kennis voor één cloud platform nodig is. Verhuizen naar een ander cloud platform betekent essentieel dat de werking van een ander ML pipeline geleerd moet worden. Bij het onderzoek zou ook het versimpelen van ML onderzocht worden. Dit is helaas niet aan bod gekomen door tijdsgebrek. In \autoref{subsec:ch4-machine-learning-versimpelen} is wel advies gegeven over het versimpelen. Aan de hand van het advies zou een experiment opgesteld worden om het advies te beproeven.

Uit het onderzoek bleek dat de orkestratietool Pulumi een geschikte keuze is om verder mee te gaan. Het implementeren van de tool sprak echter het onderzoek tegen. Dit komt doordat bij het onderzoek een experiment is uitgevoerd waarbij één taak wordt uitgevoerd. Zodra er meerdere taken achter elkaar gedaan moeten worden, vertoont de tool ongewenst gedrag. Met een uitgebreider experiment waarbij meerdere taken worden uitgevoerd zou dit probleem wellicht eerder naar boven zijn gekomen.