\styledchapter[Discussie]{discussie}
Gedurende de scriptie is literatuuronderzoek gedaan naar ML pipelines en orkestratietools. Daarnaast zijn een aantal experimenten uitgevoerd om de potentie van een ML pipeline en orkestratietool te valideren. 

De resultaten van het experiment met ML pipelines laten zien dat het trainen van modellen op een gestructureerde en reproduceerbare wijze gedaan kan worden. In \autoref{sec:ch4-advies} is uitgelegd hoe ML versimpeld kan worden voor de developer door extra stappen toe te voegen. Dit kan niet alleen gebruikt worden door NGTI maar ook andere bedrijven die geïnteresseerd zijn in het toepassen van ML. Een stap verder zou zijn dat een standaard wordt geïntroduceerd dat wordt toegepast door industrieleiders zoals Google, Microsoft en Azure. Momenteel hebben ze hun eigen variant wat betekent dat specifieke kennis voor één cloud platform nodig is. Verhuizen naar een ander cloud platform betekent essentieel dat de werking van een ander ML pipeline geleerd moet worden. Bij het onderzoek zou ook het versimpelen van ML onderzocht worden. Dit is helaas niet aan bod gekomen door tijdstekort. In \autoref{subsec:ch4-machine-learning-versimpelen} is wel advies gegeven over het versimpelen. Aan de hand van het advies zou een experiment opgesteld worden om het advies te beproeven.

Uit het onderzoek blijkt dat de orkestratietool Pulumi een geschikte keuze is om verder mee te werken. Het implementeren van de tool spreekt echter het onderzoek tegen. Dit komt doordat bij het onderzoek een experiment is uitgevoerd waarbij één taak wordt uitgevoerd. Zodra meerdere taken gedaan moeten worden achter elkaar, vertoont de tool ongewenst gedrag. Dit kon voorkomen worden door twee of meerdere acties te programmeren om uit te voeren bij het experiment.