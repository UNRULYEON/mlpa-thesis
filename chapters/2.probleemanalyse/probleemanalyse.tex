\styledchapter[Probleemanalyse]{probleemanalyse}
Zoals beschreven in \autoref{sec:aanleiding-opdracht} wilt NGTI ML toepassen om haar apps slimmer te maken. Hier zijn een aantal redenen voor, onder andere om de gebruikerservaring te verbeteren en om een voorsprong te hebben op concurrenten.

Het 'slimmer' maken van applicaties kan op verschillende manieren, maar met machine-learning kan een platform gebouwd worden waarmee elke richting op gegaan kan worden. Om machine-learning te implementeren in haar applicaties loopt NGTI tegen een aantal obstakels aan, namelijk: expertise vereist in het ML domein, benodigde tijd om een pipeline op te zetten en vendor lock-in.

\section{Obstakels voor NGTI}\label{sec:obstakels-voor-ngti}
NGTI loopt tegen de voorgenoemde obstakels aan omdat NGTI weinig ervaring heeft met ML. In samenwerking met een extern bedrijf worden modellen getraind die vervolgens gebruikt worden in apps van NGTI. Om zelf modellen te trainen heeft NGTI kennis over ML, ML pipelines en tijd nodig. Bovendien wilt NGTI niet bij één cloud computing platform haar infrastructuur opzetten maar gemakkelijk kunnen schakelen tussen platformen. De obstakels worden in de volgende koppen verduidelijkt.

\subsection{Expertise Machine Learning}\label{subsec:expertise-machine-learning}
ML is ingewikkeld en diepgaand onderwerp. Om een model te trainen is kennis nodig van verschillende domeinen: data mining, software engineering en statistieken. Doordat er voorkennis nodig is om een model te trainen en een pipeline goed op te zetten, is het vaak te hoogdrempelig voor developers om een start te maken met ML. De expertise is daarnaast niet in een korte tijd te vergaren.

\subsection{Opzetten pipeline}\label{subsec:opzetten-pipeline}
Bovenop de complexiteit van ML zelf bestaan er verschillende manieren om een model te trainen. Het opzetten van ML pipelines is daar een van. Een pipeline is een workflow dat bestaat uit een aantal stappen die doorgelopen worden om een model te trainen. In elke stap worden acties uitgevoerd, zoals het verwijderen van onbruikbare data of de prestatie van modellen vergelijken en een rapport met uitslagen genereren. Het opzetten van zo een pipeline én de actie(s) in de stappen definiëren kost tijd en vereist specifieke kennis. Daarnaast zijn de stappen en acties vaak hetzelfde voor verschillende pipelines. Het automatiseren en hergebruiken van stappen en acties tussen pipelines zou tot onder andere tijdwinst en het verminderen van herhaling van code kunnen leiden.

\subsection{Vendor lock-in}\label{subsec:vendor-lock-in}
Er bestaan een aantal diensten, zogenoemde \acrfull{paas}, waarbij je een pipeline kan opzetten en acties kan definiëren. Een van de problemen met een PaaS is vendor lock-in. Dit betekent dat, als er eenmaal een pipeline is opgezet, de overdraagbaarheid van de pipeline naar een andere PaaS vrijwel onmogelijk is. Ook zijn de opties en mogelijkheden om uit te breiden in de toekomst gelimiteerd. 

\section{Vooronderzoek naar bestaande oplossingen}\label{sec:vooronderzoek-naar-bestaande-oplossingen}
Het gebruik van ML pipelines is geen nieuwe techniek en is mogelijk bij \glsplural{paas} en bedrijven die zich specialiseren in ML pipelines. Het gemakt met zulke services is dat de gebruiker gelijk kan beginnen met het trainen van ML modellen en zich niet zorgen hoeft te maken over infrastructurele details. Echter is er sprake van vendor lock-in en kunnen services van deze bedrijven niet gebruikt worden.

Gedurende de vooronderzoek zijn "Infrastructure as Code" frameworks naar voren gekomen. Dit zijn frameworks waarmee, middels code, een infrastructure binnen een \gls{paas} opgezet kan worden. Dit kan gebruikt worden als onderdeel van de PoC en wordt in een van de deelvragen verder onderzocht.

% \section{Bestaande oplossingen om pipelines op te zetten}\label{sec:bestaande-oplossingen-om-pipelines-op-te-zetten}
% ML pipelines gebruiken binnen een cloud platform is geen nieuwe techniek. Dit is al enige tijd mogelijk bij platform-as-a-service (PaaS) bedrijven. Azure en Google cloud zijn PaaS bedrijven waarbij bijvoorbeeld een server of database gehuurd kan worden. Daarnaast bestaan er bedrijven dat zich specialiseren in ML pipelines en dat als enige service bieden. Het enige nadeel is dat vendor lock-in inherent is. In \autoref{subsec:machine-learning-pipeline-specifieke-service} en \autoref{subsec:cloud-computing-platformen} wordt uitgelegd wat vendor lock-in is en waarom de service van deze bedrijven niet geschikt it.

% Gedurende het vooronderzoek zijn frameworks dat cloud computing platformen zoals Azure en Google Cloud kan beheren. Het is mogelijk om programmatisch te communiceren met een platform. Dit geeft de mogelijkheid om een ML pipeline op te zetten in het gewenste systeem. De uitleg en bevindingen van deze frameworks is te lezen in \autoref{subsec:frameworks-om-cloud-computing-platformen-te-beheren}.

% \subsection{Machine learning pipeline specifieke service}\label{subsec:machine-learning-pipeline-specifieke-service}
% Bedrijven zoals Algorithmia \cite{algorithmia-website} en Valohai \cite{valohai-website} bieden alleen diensten om pipelines op te zetten. Ze zorgen voor het databehoud dat door de gebruiker wordt geüpload en het trainen van het model. Verder kan er toezicht gehouden worden op de kosten, beschikbaarheid en prestatie van het model. Valohai heeft ook documentatie over hoe haar service werkt en een aantal blog posts die bij het ontwerpen van het systeem relevant zouden kunnen zijn. 

% \subsection{Cloud computing platformen}\label{subsec:cloud-computing-platformen}
% De drie grote cloud computing platformen Amazon, Azure en Google hebben meer te bieden dan alleen een pipeline opzetten, zoals het hosten van een website, database of virtuele server. De cloud computing platformen hebben hetzelfde probleem als de machine learning pipeline specifieke services; vendor lock-in is onvermijdelijk. Wat wel een mogelijkheid zou kunnen zijn is dat de andere services van de cloud computing platformen gebruikt kunnen worden als onderdeel van het systeem.

% Het systeem zou bijvoorbeeld een server kunnen aanmaken, een model trainen, het resultaat downloaden en vervolgens de server verwijderen. Om dit zonder de grafisch interface te doen kan er gebruik worden gemaakt van frameworks die interacteert met het platform.

% \subsection{Frameworks om cloud computing platformen te beheren}\label{subsec:frameworks-om-cloud-computing-platformen-te-beheren}
% Een framework dat cloud computing platformen kan beheren is Terraform \cite{terraform}. Met Terraform is het mogelijk om een plan te schrijven waarin bijvoorbeeld staat welke type server nodig is. Bij het uitvoeren van het plan spreekt Terraform een cloud computing platform naar keuze aan om de server op te starten. Terraform kan vervolgens controleren of de server draait en de server afsluiten wanneer het niet meer nodig is.

% Kubeflow \cite{kubeflow} is een ander framework waarmee een pipeline kan worden opgezet. Het verschil met Terraform is dat Terraform flexibeler is met wat er aangemaakt kan worden op een cloud computing platform. Kubeflow kan alleen een pipeline uitrollen. Een andere framework zoals Kubeflow is Apache Beam \cite{apache-beam}.

\section{Doelstelling}\label{sec:doelstelling}
Om haar doel, de gebruikerservaring van apps verbeteren en een voorsprong hebben op concurrent, te bereiken is NGTI van plan ML pipelines te gebruiken om ML toe te passen. De gewenste oplossing is een systeem waarbij developers met weinig tot geen kennis een model kunnen trainen. Het systeem moet de infrastructurele taken voor zich nemen, zoals het opzetten van een pipeline en de stappen en acties automatiseren. Daarnaast moet een ML pipeline pijnloos doorlopen kunnen worden op verschillende platformen zodat het systeem platform-agnostisch is.

\section{Hoofd- en deelvragen}\label{sec:hoofd-en-deelvragen}
Uitgaand van de drie obstakels kan de hoofdvraag als volgt worden geformuleerd:

\begin{quoting}
  \begin{center}
    \textbf{
      \textit{
        In welke mate kan een machine learning pipeline worden geautomatiseerd onafhankelijk van het onderliggende cloud computing platform?
      }
    }
  \end{center}
\end{quoting}\smallskip

De hoofdvraag kan worden onderbouwd met vier deelvragen. Om te beginnen is het verstandig om te weten welke stappen er in een machine learning pipeline zit:

\begin{quoting}
  \begin{center}
    \textit{
      Waar bestaat een machine learning pipeline uit?
    }
  \end{center}
\end{quoting}\smallskip

Daarnaast is een framework nodig dat, door middel van code, verschillende cloud computing platformen kan beheren:

\begin{quoting}
  \begin{center}
    \textit{
      Hoe kan een framework verschillende cloud computing platformen beheren om een machine learning pipeline op te zetten?
    }
  \end{center}
\end{quoting}\smallskip

Ten slotte wordt een PoC gemaakt om te laten zien of het probleem oplosbaar is. Hiervoor is een doordachte voorbereiden onmisbaar:

\begin{quoting}
  \begin{center}
    \textit{
      Hoe ziet de architecturale blauwdruk van een applicatie, waarmee een platform-onafhankelijk machine learning pipeline opgezet kan worden, eruit?
    }
  \end{center}
\end{quoting}


% -----------

% \newpage

% \begin{quoting}
%   \begin{center}
%     \textbf{
%       \textit{
%         In welke mate kan een machine learning pipeline worden geautomatiseerd onafhankelijk van de onderliggende cloud computing platform?
%       }
%     }
%   \end{center}
% \end{quoting}\smallskip

% \begin{quoting}
%   \begin{center}
%     \textit{
%       Uit welke stappen bestaat een machine learning pipeline?
%     }
%   \end{center}
% \end{quoting}\smallskip

% \begin{quoting}
%   \begin{center}
%     \textit{
%       Welke framework om een cloud computing platform te beheren voldoet 
%     }
%   \end{center}
% \end{quoting}\smallskip

% \begin{quoting}
%   \begin{center}
%     \textit{
%       Hoe ziet de architecturale blauwdruk van een applicatie, waarmee een machine learning pipeline kan worden opgezet, die modulaire acties geautomatiseerd in stappen samenstelt eruit?
%     }
%   \end{center}
% \end{quoting}

% ------

% Uitgaand van de drie obstakels kan de hoofdvraag als volgt worden geformuleerd:

% \begin{quoting}
%   \begin{center}
%     \textbf{
%       \textit{
%         In welke mate kan een machine learning pipeline worden geautomatiseerd onafhankelijk van de onderliggende cloud computing platform?
%       }
%     }
%   \end{center}
% \end{quoting}\smallskip

% De hoofdvraag kan worden onderbouwd met vier deelvragen. Om te beginnen is het verstandig om te weten welke stappen er in een machine learning pipeline zit:

% \begin{quoting}
%   \begin{center}
%     \textit{
%       Uit welke stappen bestaat een machine learning pipeline?
%     }
%   \end{center}
% \end{quoting}\smallskip

% Vervolgens kunnen de verschillende cloud computing platformen in kaart worden gebracht:

% \begin{quoting}
%   \begin{center}
%     \textit{
%       Wat zijn de verschillen en overeenkomsten tussen cloud computing platformen waarmee een machine learning pipeline kan worden opgezet?
%     }
%   \end{center}
% \end{quoting}\smallskip

% Verder kan het handig zijn om meerdere platformen aan te spreken. Dit zou kunnen met een bestaand framework. Hierbij is het, net als de vorige deelvraag, belangrijk om te weten welke frameworks er zijn:

% \begin{quoting}
%   \begin{center}
%     \textit{
%       Wat zijn de verschillen en overeenkomsten tussen frameworks waarmee cloud computing platformen beheerd kunnen worden?
%     }
%   \end{center}
% \end{quoting}\smallskip

% Ten slotte wordt een PoC gemaakt om te laten zien of het probleem oplosbaar is. Hiervoor is een doordachte voorbereiding onmisbaar:

% \begin{quoting}
%   \begin{center}
%     \textit{
%       Hoe ziet de architecturale blauwdruk van een applicatie, waarmee een machine learning pipeline kan worden opgezet, die modulaire acties geautomatiseerd in stappen samenstelt, en die platform-onafhankelijk is, eruit?
%     }
%   \end{center}
% \end{quoting}